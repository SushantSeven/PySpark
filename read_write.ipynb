{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local\")\\\n",
    "                    .appName(\"read_write_ops\")\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv file from hdfs and write to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",True).option(\"separator\",\",\").load(\"hdfs://localhost:9000/csv_wordcount/iris.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.write.csv(\"csv_to_csv_read.csv\", mode=\"overwrite\", header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv file from local to and write to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",True).option(\"separator\",\",\").load(\"ODI-data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"csv\").option(\"header\",True).option(\"separator\",\",\").save(\"hdfs://localhost:9000/csv_wordcount/odi_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read json from local and write to hdfs as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|color|fruit| size|\n",
      "+-----+-----+-----+\n",
      "|  Red|Apple|Large|\n",
      "+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"multiline\",True).json(\"sample1.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.json(\"hdfs://localhost:9000/csv_wordcount/imported_json.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read json file from hdfs and write to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|color|fruit| size|\n",
      "+-----+-----+-----+\n",
      "|  Red|Apple|Large|\n",
      "+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df = spark.read.json(\"hdfs://localhost:9000/csv_wordcount/imported_json.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.json(\"imported_json.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read json file from local and write it to hdfs as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|color|fruit| size|\n",
      "+-----+-----+-----+\n",
      "|  Red|Apple|Large|\n",
      "+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df = spark.read.option(\"multiline\",True).json(\"sample1.json\")\n",
    "df = spark.read.format(\"json\").option(\"multiline\",True).load(\"sample1.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"csv\").option(\"header\",True).option(\"separator\",\",\").save(\"hdfs://localhost:9000/csv_wordcount/imported_json.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read parquet file from local and save it to hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|              model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "|          Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
      "|      Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
      "|         Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
      "|     Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
      "|  Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
      "|            Valiant|18.1|  6|225.0|105|2.76| 3.46|20.22|  1|  0|   3|   1|\n",
      "|         Duster 360|14.3|  8|360.0|245|3.21| 3.57|15.84|  0|  0|   3|   4|\n",
      "|          Merc 240D|24.4|  4|146.7| 62|3.69| 3.19| 20.0|  1|  0|   4|   2|\n",
      "|           Merc 230|22.8|  4|140.8| 95|3.92| 3.15| 22.9|  1|  0|   4|   2|\n",
      "|           Merc 280|19.2|  6|167.6|123|3.92| 3.44| 18.3|  1|  0|   4|   4|\n",
      "|          Merc 280C|17.8|  6|167.6|123|3.92| 3.44| 18.9|  1|  0|   4|   4|\n",
      "|         Merc 450SE|16.4|  8|275.8|180|3.07| 4.07| 17.4|  0|  0|   3|   3|\n",
      "|         Merc 450SL|17.3|  8|275.8|180|3.07| 3.73| 17.6|  0|  0|   3|   3|\n",
      "|        Merc 450SLC|15.2|  8|275.8|180|3.07| 3.78| 18.0|  0|  0|   3|   3|\n",
      "| Cadillac Fleetwood|10.4|  8|472.0|205|2.93| 5.25|17.98|  0|  0|   3|   4|\n",
      "|Lincoln Continental|10.4|  8|460.0|215| 3.0|5.424|17.82|  0|  0|   3|   4|\n",
      "|  Chrysler Imperial|14.7|  8|440.0|230|3.23|5.345|17.42|  0|  0|   3|   4|\n",
      "|           Fiat 128|32.4|  4| 78.7| 66|4.08|  2.2|19.47|  1|  1|   4|   1|\n",
      "|        Honda Civic|30.4|  4| 75.7| 52|4.93|1.615|18.52|  1|  1|   4|   2|\n",
      "|     Toyota Corolla|33.9|  4| 71.1| 65|4.22|1.835| 19.9|  1|  1|   4|   1|\n",
      "+-------------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= spark.read.format(\"parquet\").load(\"MT-cars.parquet\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"parquet\").save(\"hdfs://localhost:9000/csv_wordcount/mtcars_parq.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
